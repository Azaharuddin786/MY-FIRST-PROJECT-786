{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10 datasets accuracy 86%",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtLVZTdthR36HAO8fDoEhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azaharuddin786/MY-FIRST-PROJECT-786/blob/main/cifar10_datasets_accuracy_86_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization\n",
        "from keras.layers import Conv2D,MaxPool2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "kZmDQf07APN_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "  lrate = 0.001\n",
        "  if epoch > 75:\n",
        "    lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "      lrate = 0.0003\n",
        "      return lrate"
      ],
      "metadata": {
        "id": "3x0V4eTqQN8z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tac77UAPQ2Hm",
        "outputId": "1b3f8118-cd96-43f8-a7e8-56b96f8b3af9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "id": "l9XqfG7wRak1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "metadata": {
        "id": "aJZaPrSLUI_4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        "weight_decay = 1e-4"
      ],
      "metadata": {
        "id": "tsZ3GO4_VH-M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "eRQEuuryWAhT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.pooling import MaxPooling2D\n",
        "model.add(Conv2D(32, (3,3), padding='same',kernel_regularizer=regularizers.l2(weight_decay),input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTmLvL69WLE9",
        "outputId": "cd566936-0e38-4961-d955-a5edd4a48eee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "fv74wIKvdija"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "batch_size = 64\n",
        "optimizer='adam'"
      ],
      "metadata": {
        "id": "pahbkNeaeQJ5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss= 'CategoricalCrossentropy', optimizer=optimizer, metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "WIG4iYYVdi1X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6wVF3RqdjBl",
        "outputId": "227fc479-a79b-4801-cb04-76317c706415"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=124, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPo4VfaKdjEa",
        "outputId": "f09d563f-aa78-46d6-9575-cd0a1a4f0175"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/124\n",
            "782/782 [==============================] - 21s 12ms/step - loss: 1.6789 - accuracy: 0.4814 - val_loss: 1.0711 - val_accuracy: 0.6485\n",
            "Epoch 2/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.0674 - accuracy: 0.6501 - val_loss: 0.8953 - val_accuracy: 0.7056\n",
            "Epoch 3/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8929 - accuracy: 0.7093 - val_loss: 0.8432 - val_accuracy: 0.7290\n",
            "Epoch 4/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8037 - accuracy: 0.7432 - val_loss: 0.7474 - val_accuracy: 0.7633\n",
            "Epoch 5/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7287 - accuracy: 0.7713 - val_loss: 0.7409 - val_accuracy: 0.7753\n",
            "Epoch 6/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6874 - accuracy: 0.7906 - val_loss: 0.6711 - val_accuracy: 0.7980\n",
            "Epoch 7/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6416 - accuracy: 0.8071 - val_loss: 0.6550 - val_accuracy: 0.8084\n",
            "Epoch 8/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6101 - accuracy: 0.8232 - val_loss: 0.6445 - val_accuracy: 0.8175\n",
            "Epoch 9/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5890 - accuracy: 0.8342 - val_loss: 0.6474 - val_accuracy: 0.8200\n",
            "Epoch 10/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5726 - accuracy: 0.8419 - val_loss: 0.6602 - val_accuracy: 0.8256\n",
            "Epoch 11/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5559 - accuracy: 0.8494 - val_loss: 0.6266 - val_accuracy: 0.8328\n",
            "Epoch 12/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5451 - accuracy: 0.8564 - val_loss: 0.6130 - val_accuracy: 0.8397\n",
            "Epoch 13/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5307 - accuracy: 0.8638 - val_loss: 0.6541 - val_accuracy: 0.8295\n",
            "Epoch 14/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5203 - accuracy: 0.8693 - val_loss: 0.6536 - val_accuracy: 0.8334\n",
            "Epoch 15/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5147 - accuracy: 0.8723 - val_loss: 0.6854 - val_accuracy: 0.8251\n",
            "Epoch 16/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5111 - accuracy: 0.8753 - val_loss: 0.6729 - val_accuracy: 0.8346\n",
            "Epoch 17/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5033 - accuracy: 0.8795 - val_loss: 0.6339 - val_accuracy: 0.8446\n",
            "Epoch 18/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4971 - accuracy: 0.8832 - val_loss: 0.6544 - val_accuracy: 0.8479\n",
            "Epoch 19/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4893 - accuracy: 0.8861 - val_loss: 0.6417 - val_accuracy: 0.8480\n",
            "Epoch 20/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4884 - accuracy: 0.8877 - val_loss: 0.6346 - val_accuracy: 0.8510\n",
            "Epoch 21/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4838 - accuracy: 0.8914 - val_loss: 0.6866 - val_accuracy: 0.8334\n",
            "Epoch 22/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4804 - accuracy: 0.8951 - val_loss: 0.6583 - val_accuracy: 0.8467\n",
            "Epoch 23/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4809 - accuracy: 0.8954 - val_loss: 0.6423 - val_accuracy: 0.8524\n",
            "Epoch 24/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4717 - accuracy: 0.8967 - val_loss: 0.6467 - val_accuracy: 0.8514\n",
            "Epoch 25/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4684 - accuracy: 0.9005 - val_loss: 0.6405 - val_accuracy: 0.8552\n",
            "Epoch 26/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4681 - accuracy: 0.9012 - val_loss: 0.6744 - val_accuracy: 0.8449\n",
            "Epoch 27/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4666 - accuracy: 0.9025 - val_loss: 0.6567 - val_accuracy: 0.8502\n",
            "Epoch 28/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4613 - accuracy: 0.9037 - val_loss: 0.6650 - val_accuracy: 0.8530\n",
            "Epoch 29/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4593 - accuracy: 0.9057 - val_loss: 0.6468 - val_accuracy: 0.8560\n",
            "Epoch 30/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4621 - accuracy: 0.9069 - val_loss: 0.6538 - val_accuracy: 0.8528\n",
            "Epoch 31/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4582 - accuracy: 0.9072 - val_loss: 0.6793 - val_accuracy: 0.8502\n",
            "Epoch 32/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4553 - accuracy: 0.9088 - val_loss: 0.6858 - val_accuracy: 0.8469\n",
            "Epoch 33/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4509 - accuracy: 0.9097 - val_loss: 0.6519 - val_accuracy: 0.8565\n",
            "Epoch 34/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4489 - accuracy: 0.9126 - val_loss: 0.6686 - val_accuracy: 0.8532\n",
            "Epoch 35/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4488 - accuracy: 0.9108 - val_loss: 0.6643 - val_accuracy: 0.8564\n",
            "Epoch 36/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4490 - accuracy: 0.9131 - val_loss: 0.6614 - val_accuracy: 0.8535\n",
            "Epoch 37/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4432 - accuracy: 0.9140 - val_loss: 0.6718 - val_accuracy: 0.8556\n",
            "Epoch 38/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4486 - accuracy: 0.9131 - val_loss: 0.6676 - val_accuracy: 0.8570\n",
            "Epoch 39/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4475 - accuracy: 0.9138 - val_loss: 0.6551 - val_accuracy: 0.8547\n",
            "Epoch 40/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4398 - accuracy: 0.9168 - val_loss: 0.6637 - val_accuracy: 0.8579\n",
            "Epoch 41/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4455 - accuracy: 0.9145 - val_loss: 0.6526 - val_accuracy: 0.8635\n",
            "Epoch 42/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4416 - accuracy: 0.9157 - val_loss: 0.6704 - val_accuracy: 0.8569\n",
            "Epoch 43/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4380 - accuracy: 0.9167 - val_loss: 0.6529 - val_accuracy: 0.8571\n",
            "Epoch 44/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4350 - accuracy: 0.9182 - val_loss: 0.6783 - val_accuracy: 0.8625\n",
            "Epoch 45/124\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.4320 - accuracy: 0.9185 - val_loss: 0.6626 - val_accuracy: 0.8611\n",
            "Epoch 46/124\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.4351 - accuracy: 0.9182 - val_loss: 0.6582 - val_accuracy: 0.8631\n",
            "Epoch 47/124\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.4364 - accuracy: 0.9177 - val_loss: 0.6698 - val_accuracy: 0.8539\n",
            "Epoch 48/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4341 - accuracy: 0.9188 - val_loss: 0.6629 - val_accuracy: 0.8618\n",
            "Epoch 49/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4331 - accuracy: 0.9202 - val_loss: 0.6923 - val_accuracy: 0.8556\n",
            "Epoch 50/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4361 - accuracy: 0.9193 - val_loss: 0.6550 - val_accuracy: 0.8614\n",
            "Epoch 51/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4328 - accuracy: 0.9217 - val_loss: 0.6976 - val_accuracy: 0.8520\n",
            "Epoch 52/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4283 - accuracy: 0.9209 - val_loss: 0.6886 - val_accuracy: 0.8590\n",
            "Epoch 53/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4337 - accuracy: 0.9209 - val_loss: 0.6773 - val_accuracy: 0.8615\n",
            "Epoch 54/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4328 - accuracy: 0.9206 - val_loss: 0.6758 - val_accuracy: 0.8555\n",
            "Epoch 55/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4270 - accuracy: 0.9237 - val_loss: 0.6455 - val_accuracy: 0.8662\n",
            "Epoch 56/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4242 - accuracy: 0.9244 - val_loss: 0.6690 - val_accuracy: 0.8621\n",
            "Epoch 57/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4264 - accuracy: 0.9231 - val_loss: 0.6779 - val_accuracy: 0.8583\n",
            "Epoch 58/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4265 - accuracy: 0.9239 - val_loss: 0.6607 - val_accuracy: 0.8623\n",
            "Epoch 59/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4202 - accuracy: 0.9254 - val_loss: 0.6868 - val_accuracy: 0.8594\n",
            "Epoch 60/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4262 - accuracy: 0.9227 - val_loss: 0.6579 - val_accuracy: 0.8632\n",
            "Epoch 61/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4245 - accuracy: 0.9240 - val_loss: 0.6698 - val_accuracy: 0.8611\n",
            "Epoch 62/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4232 - accuracy: 0.9232 - val_loss: 0.6865 - val_accuracy: 0.8570\n",
            "Epoch 63/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4220 - accuracy: 0.9251 - val_loss: 0.6658 - val_accuracy: 0.8611\n",
            "Epoch 64/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4168 - accuracy: 0.9270 - val_loss: 0.6956 - val_accuracy: 0.8599\n",
            "Epoch 65/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4174 - accuracy: 0.9272 - val_loss: 0.6717 - val_accuracy: 0.8602\n",
            "Epoch 66/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4250 - accuracy: 0.9231 - val_loss: 0.6682 - val_accuracy: 0.8614\n",
            "Epoch 67/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4199 - accuracy: 0.9249 - val_loss: 0.6590 - val_accuracy: 0.8664\n",
            "Epoch 68/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4179 - accuracy: 0.9256 - val_loss: 0.6690 - val_accuracy: 0.8590\n",
            "Epoch 69/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4201 - accuracy: 0.9256 - val_loss: 0.6819 - val_accuracy: 0.8565\n",
            "Epoch 70/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4184 - accuracy: 0.9263 - val_loss: 0.6907 - val_accuracy: 0.8592\n",
            "Epoch 71/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4150 - accuracy: 0.9277 - val_loss: 0.6915 - val_accuracy: 0.8587\n",
            "Epoch 72/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4227 - accuracy: 0.9255 - val_loss: 0.7004 - val_accuracy: 0.8571\n",
            "Epoch 73/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4234 - accuracy: 0.9242 - val_loss: 0.6665 - val_accuracy: 0.8634\n",
            "Epoch 74/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4154 - accuracy: 0.9278 - val_loss: 0.6586 - val_accuracy: 0.8640\n",
            "Epoch 75/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4184 - accuracy: 0.9258 - val_loss: 0.6833 - val_accuracy: 0.8603\n",
            "Epoch 76/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4173 - accuracy: 0.9266 - val_loss: 0.6868 - val_accuracy: 0.8573\n",
            "Epoch 77/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4180 - accuracy: 0.9272 - val_loss: 0.6716 - val_accuracy: 0.8639\n",
            "Epoch 78/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4123 - accuracy: 0.9278 - val_loss: 0.6608 - val_accuracy: 0.8684\n",
            "Epoch 79/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4149 - accuracy: 0.9284 - val_loss: 0.6769 - val_accuracy: 0.8615\n",
            "Epoch 80/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4117 - accuracy: 0.9285 - val_loss: 0.7117 - val_accuracy: 0.8540\n",
            "Epoch 81/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4081 - accuracy: 0.9302 - val_loss: 0.6601 - val_accuracy: 0.8646\n",
            "Epoch 82/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4118 - accuracy: 0.9275 - val_loss: 0.6691 - val_accuracy: 0.8667\n",
            "Epoch 83/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4107 - accuracy: 0.9295 - val_loss: 0.6823 - val_accuracy: 0.8618\n",
            "Epoch 84/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4113 - accuracy: 0.9288 - val_loss: 0.6724 - val_accuracy: 0.8623\n",
            "Epoch 85/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4087 - accuracy: 0.9313 - val_loss: 0.6846 - val_accuracy: 0.8651\n",
            "Epoch 86/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4096 - accuracy: 0.9297 - val_loss: 0.6959 - val_accuracy: 0.8622\n",
            "Epoch 87/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4122 - accuracy: 0.9288 - val_loss: 0.6382 - val_accuracy: 0.8688\n",
            "Epoch 88/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4081 - accuracy: 0.9296 - val_loss: 0.6784 - val_accuracy: 0.8642\n",
            "Epoch 89/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4154 - accuracy: 0.9266 - val_loss: 0.6548 - val_accuracy: 0.8666\n",
            "Epoch 90/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4073 - accuracy: 0.9308 - val_loss: 0.7073 - val_accuracy: 0.8536\n",
            "Epoch 91/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4095 - accuracy: 0.9307 - val_loss: 0.6659 - val_accuracy: 0.8645\n",
            "Epoch 92/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4130 - accuracy: 0.9284 - val_loss: 0.6892 - val_accuracy: 0.8626\n",
            "Epoch 93/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4076 - accuracy: 0.9315 - val_loss: 0.6454 - val_accuracy: 0.8677\n",
            "Epoch 94/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4045 - accuracy: 0.9321 - val_loss: 0.6903 - val_accuracy: 0.8609\n",
            "Epoch 95/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4100 - accuracy: 0.9292 - val_loss: 0.6856 - val_accuracy: 0.8599\n",
            "Epoch 96/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4078 - accuracy: 0.9309 - val_loss: 0.6649 - val_accuracy: 0.8656\n",
            "Epoch 97/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4060 - accuracy: 0.9311 - val_loss: 0.6925 - val_accuracy: 0.8610\n",
            "Epoch 98/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4072 - accuracy: 0.9301 - val_loss: 0.6964 - val_accuracy: 0.8630\n",
            "Epoch 99/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4060 - accuracy: 0.9304 - val_loss: 0.6749 - val_accuracy: 0.8633\n",
            "Epoch 100/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4042 - accuracy: 0.9325 - val_loss: 0.6670 - val_accuracy: 0.8680\n",
            "Epoch 101/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4070 - accuracy: 0.9311 - val_loss: 0.6747 - val_accuracy: 0.8632\n",
            "Epoch 102/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4049 - accuracy: 0.9318 - val_loss: 0.6816 - val_accuracy: 0.8625\n",
            "Epoch 103/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4038 - accuracy: 0.9318 - val_loss: 0.6774 - val_accuracy: 0.8629\n",
            "Epoch 104/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4038 - accuracy: 0.9324 - val_loss: 0.6697 - val_accuracy: 0.8598\n",
            "Epoch 105/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4048 - accuracy: 0.9314 - val_loss: 0.6803 - val_accuracy: 0.8649\n",
            "Epoch 106/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4051 - accuracy: 0.9313 - val_loss: 0.6813 - val_accuracy: 0.8639\n",
            "Epoch 107/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4110 - accuracy: 0.9279 - val_loss: 0.6799 - val_accuracy: 0.8611\n",
            "Epoch 108/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4005 - accuracy: 0.9337 - val_loss: 0.6604 - val_accuracy: 0.8654\n",
            "Epoch 109/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4039 - accuracy: 0.9306 - val_loss: 0.6897 - val_accuracy: 0.8644\n",
            "Epoch 110/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3981 - accuracy: 0.9336 - val_loss: 0.6721 - val_accuracy: 0.8671\n",
            "Epoch 111/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4035 - accuracy: 0.9334 - val_loss: 0.6678 - val_accuracy: 0.8615\n",
            "Epoch 112/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4003 - accuracy: 0.9321 - val_loss: 0.6503 - val_accuracy: 0.8677\n",
            "Epoch 113/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4007 - accuracy: 0.9335 - val_loss: 0.6571 - val_accuracy: 0.8650\n",
            "Epoch 114/124\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4009 - accuracy: 0.9322 - val_loss: 0.6644 - val_accuracy: 0.8634\n",
            "Epoch 115/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3971 - accuracy: 0.9335 - val_loss: 0.6559 - val_accuracy: 0.8689\n",
            "Epoch 116/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3987 - accuracy: 0.9343 - val_loss: 0.6452 - val_accuracy: 0.8667\n",
            "Epoch 117/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.4051 - accuracy: 0.9306 - val_loss: 0.6673 - val_accuracy: 0.8667\n",
            "Epoch 118/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3992 - accuracy: 0.9338 - val_loss: 0.6662 - val_accuracy: 0.8648\n",
            "Epoch 119/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.4043 - accuracy: 0.9319 - val_loss: 0.6910 - val_accuracy: 0.8596\n",
            "Epoch 120/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3960 - accuracy: 0.9347 - val_loss: 0.6714 - val_accuracy: 0.8667\n",
            "Epoch 121/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3968 - accuracy: 0.9343 - val_loss: 0.6830 - val_accuracy: 0.8632\n",
            "Epoch 122/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3995 - accuracy: 0.9343 - val_loss: 0.6911 - val_accuracy: 0.8604\n",
            "Epoch 123/124\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3927 - accuracy: 0.9358 - val_loss: 0.6709 - val_accuracy: 0.8649\n",
            "Epoch 124/124\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3993 - accuracy: 0.9331 - val_loss: 0.6942 - val_accuracy: 0.8630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc664a54b50>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test,y_test, verbose=0)\n",
        "print(\"accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2VYpEMfAZt9",
        "outputId": "4d1722cb-b1ac-4fac-ea69-52fee149811b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 86.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fv9WijJrAY6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n2_gQ3APdjPq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oFLyMgjkdjSi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BsSfPP-EdjVX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5Wuol5EjdjYz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CNLKwofPc6pm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hln9ghOdc65h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TA_mfGREc7GG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qsX7eAdITwcD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Qh_SuLjTwrx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-IaXPXiwTwuP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XDWjmtxaTwwn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ZJSA5m6Twzc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x2KZ36uLTw20"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XeGxIEUeTxCP"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}