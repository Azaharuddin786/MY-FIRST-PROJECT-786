{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.81%%",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXf96i/rOWVfAAqYnfNl12",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azaharuddin786/MY-FIRST-PROJECT-786/blob/main/Untitled12_81_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AL6S2G6qFtXd"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    elif epoch > 100:\n",
        "        lrate = 0.0003        \n",
        "    return lrate"
      ],
      "metadata": {
        "id": "gcHjaOxSGEE-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "id": "Nd0lSdq7GKHJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "metadata": {
        "id": "ziGKnU1XGTAU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)"
      ],
      "metadata": {
        "id": "CKWAANygGTQY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkhrjU4CGnyS",
        "outputId": "c4605fef-8422-414b-b66f-2d8d26df8741"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "rndEZtCUGTTE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "batch_size= 64"
      ],
      "metadata": {
        "id": "-PtvO1tkJN4o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "uNKU5A2oJbvi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='mse', optimizer=rmsprop, metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzw7oQD7HYBg",
        "outputId": "c6d7382b-7e61-4485-d327-190f4b4f7306"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "781/781 [==============================] - 56s 58ms/step - loss: 0.1111 - accuracy: 0.3860 - val_loss: 0.0804 - val_accuracy: 0.5170 - lr: 0.0010\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0757 - accuracy: 0.5418 - val_loss: 0.0675 - val_accuracy: 0.5985 - lr: 0.0010\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0690 - accuracy: 0.5943 - val_loss: 0.0731 - val_accuracy: 0.5900 - lr: 0.0010\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0663 - accuracy: 0.6230 - val_loss: 0.0645 - val_accuracy: 0.6248 - lr: 0.0010\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0645 - accuracy: 0.6381 - val_loss: 0.0632 - val_accuracy: 0.6470 - lr: 0.0010\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0629 - accuracy: 0.6531 - val_loss: 0.0731 - val_accuracy: 0.6016 - lr: 0.0010\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0629 - accuracy: 0.6558 - val_loss: 0.0655 - val_accuracy: 0.6630 - lr: 0.0010\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0630 - accuracy: 0.6657 - val_loss: 0.0656 - val_accuracy: 0.6501 - lr: 0.0010\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0617 - accuracy: 0.6709 - val_loss: 0.0650 - val_accuracy: 0.6491 - lr: 0.0010\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0606 - accuracy: 0.6772 - val_loss: 0.0610 - val_accuracy: 0.6636 - lr: 0.0010\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0597 - accuracy: 0.6818 - val_loss: 0.0628 - val_accuracy: 0.6825 - lr: 0.0010\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0598 - accuracy: 0.6844 - val_loss: 0.0571 - val_accuracy: 0.7117 - lr: 0.0010\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.0593 - accuracy: 0.6887 - val_loss: 0.0787 - val_accuracy: 0.6130 - lr: 0.0010\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.0579 - accuracy: 0.6974 - val_loss: 0.0529 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0599 - accuracy: 0.6918 - val_loss: 0.0534 - val_accuracy: 0.7349 - lr: 0.0010\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0576 - accuracy: 0.6980 - val_loss: 0.0588 - val_accuracy: 0.7057 - lr: 0.0010\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.0568 - accuracy: 0.7027 - val_loss: 0.0574 - val_accuracy: 0.7126 - lr: 0.0010\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0572 - accuracy: 0.7034 - val_loss: 0.0607 - val_accuracy: 0.6997 - lr: 0.0010\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.0567 - accuracy: 0.7037 - val_loss: 0.0572 - val_accuracy: 0.7071 - lr: 0.0010\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0568 - accuracy: 0.7070 - val_loss: 0.0724 - val_accuracy: 0.6189 - lr: 0.0010\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0575 - accuracy: 0.7057 - val_loss: 0.0679 - val_accuracy: 0.6440 - lr: 0.0010\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0566 - accuracy: 0.7075 - val_loss: 0.0630 - val_accuracy: 0.6563 - lr: 0.0010\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0560 - accuracy: 0.7103 - val_loss: 0.0579 - val_accuracy: 0.6997 - lr: 0.0010\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0563 - accuracy: 0.7099 - val_loss: 0.0526 - val_accuracy: 0.7351 - lr: 0.0010\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0558 - accuracy: 0.7100 - val_loss: 0.0564 - val_accuracy: 0.7108 - lr: 0.0010\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0550 - accuracy: 0.7136 - val_loss: 0.0552 - val_accuracy: 0.7103 - lr: 0.0010\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0547 - accuracy: 0.7166 - val_loss: 0.0547 - val_accuracy: 0.7235 - lr: 0.0010\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0549 - accuracy: 0.7154 - val_loss: 0.0507 - val_accuracy: 0.7392 - lr: 0.0010\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0551 - accuracy: 0.7147 - val_loss: 0.0823 - val_accuracy: 0.5845 - lr: 0.0010\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0554 - accuracy: 0.7123 - val_loss: 0.0508 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0537 - accuracy: 0.7199 - val_loss: 0.0606 - val_accuracy: 0.6782 - lr: 0.0010\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0541 - accuracy: 0.7184 - val_loss: 0.0542 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0538 - accuracy: 0.7186 - val_loss: 0.0620 - val_accuracy: 0.6625 - lr: 0.0010\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0534 - accuracy: 0.7245 - val_loss: 0.0616 - val_accuracy: 0.6640 - lr: 0.0010\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0526 - accuracy: 0.7242 - val_loss: 0.0481 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 48s 61ms/step - loss: 0.0512 - accuracy: 0.7302 - val_loss: 0.0614 - val_accuracy: 0.6792 - lr: 0.0010\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 47s 61ms/step - loss: 0.0499 - accuracy: 0.7360 - val_loss: 0.0501 - val_accuracy: 0.7406 - lr: 0.0010\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0495 - accuracy: 0.7375 - val_loss: 0.0505 - val_accuracy: 0.7381 - lr: 0.0010\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0485 - accuracy: 0.7414 - val_loss: 0.0435 - val_accuracy: 0.7817 - lr: 0.0010\n",
            "Epoch 40/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0475 - accuracy: 0.7459 - val_loss: 0.0510 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 41/125\n",
            "781/781 [==============================] - 47s 61ms/step - loss: 0.0472 - accuracy: 0.7456 - val_loss: 0.0451 - val_accuracy: 0.7622 - lr: 0.0010\n",
            "Epoch 42/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0467 - accuracy: 0.7472 - val_loss: 0.0459 - val_accuracy: 0.7561 - lr: 0.0010\n",
            "Epoch 43/125\n",
            "781/781 [==============================] - 47s 61ms/step - loss: 0.0464 - accuracy: 0.7493 - val_loss: 0.0525 - val_accuracy: 0.7158 - lr: 0.0010\n",
            "Epoch 44/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0459 - accuracy: 0.7536 - val_loss: 0.0441 - val_accuracy: 0.7664 - lr: 0.0010\n",
            "Epoch 45/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0460 - accuracy: 0.7506 - val_loss: 0.0506 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 46/125\n",
            "781/781 [==============================] - 48s 61ms/step - loss: 0.0459 - accuracy: 0.7517 - val_loss: 0.0438 - val_accuracy: 0.7655 - lr: 0.0010\n",
            "Epoch 47/125\n",
            "781/781 [==============================] - 48s 61ms/step - loss: 0.0458 - accuracy: 0.7526 - val_loss: 0.0437 - val_accuracy: 0.7726 - lr: 0.0010\n",
            "Epoch 48/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0459 - accuracy: 0.7531 - val_loss: 0.0486 - val_accuracy: 0.7352 - lr: 0.0010\n",
            "Epoch 49/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0455 - accuracy: 0.7539 - val_loss: 0.0479 - val_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 50/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0453 - accuracy: 0.7557 - val_loss: 0.0433 - val_accuracy: 0.7764 - lr: 0.0010\n",
            "Epoch 51/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0452 - accuracy: 0.7574 - val_loss: 0.0405 - val_accuracy: 0.7954 - lr: 0.0010\n",
            "Epoch 52/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0454 - accuracy: 0.7548 - val_loss: 0.0438 - val_accuracy: 0.7702 - lr: 0.0010\n",
            "Epoch 53/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0452 - accuracy: 0.7558 - val_loss: 0.0492 - val_accuracy: 0.7391 - lr: 0.0010\n",
            "Epoch 54/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0452 - accuracy: 0.7566 - val_loss: 0.0464 - val_accuracy: 0.7522 - lr: 0.0010\n",
            "Epoch 55/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0451 - accuracy: 0.7582 - val_loss: 0.0417 - val_accuracy: 0.7836 - lr: 0.0010\n",
            "Epoch 56/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0449 - accuracy: 0.7593 - val_loss: 0.0480 - val_accuracy: 0.7466 - lr: 0.0010\n",
            "Epoch 57/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0449 - accuracy: 0.7587 - val_loss: 0.0453 - val_accuracy: 0.7617 - lr: 0.0010\n",
            "Epoch 58/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0451 - accuracy: 0.7574 - val_loss: 0.0424 - val_accuracy: 0.7815 - lr: 0.0010\n",
            "Epoch 59/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0448 - accuracy: 0.7584 - val_loss: 0.0461 - val_accuracy: 0.7532 - lr: 0.0010\n",
            "Epoch 60/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0448 - accuracy: 0.7598 - val_loss: 0.0458 - val_accuracy: 0.7546 - lr: 0.0010\n",
            "Epoch 61/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0446 - accuracy: 0.7619 - val_loss: 0.0468 - val_accuracy: 0.7545 - lr: 0.0010\n",
            "Epoch 62/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0447 - accuracy: 0.7616 - val_loss: 0.0465 - val_accuracy: 0.7495 - lr: 0.0010\n",
            "Epoch 63/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0444 - accuracy: 0.7636 - val_loss: 0.0424 - val_accuracy: 0.7808 - lr: 0.0010\n",
            "Epoch 64/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0446 - accuracy: 0.7619 - val_loss: 0.0430 - val_accuracy: 0.7765 - lr: 0.0010\n",
            "Epoch 65/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0447 - accuracy: 0.7625 - val_loss: 0.0435 - val_accuracy: 0.7764 - lr: 0.0010\n",
            "Epoch 66/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0446 - accuracy: 0.7622 - val_loss: 0.0447 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 67/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0446 - accuracy: 0.7608 - val_loss: 0.0487 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 68/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0448 - accuracy: 0.7595 - val_loss: 0.0421 - val_accuracy: 0.7849 - lr: 0.0010\n",
            "Epoch 69/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0442 - accuracy: 0.7655 - val_loss: 0.0444 - val_accuracy: 0.7675 - lr: 0.0010\n",
            "Epoch 70/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0444 - accuracy: 0.7639 - val_loss: 0.0398 - val_accuracy: 0.8006 - lr: 0.0010\n",
            "Epoch 71/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0442 - accuracy: 0.7637 - val_loss: 0.0441 - val_accuracy: 0.7712 - lr: 0.0010\n",
            "Epoch 72/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0443 - accuracy: 0.7628 - val_loss: 0.0412 - val_accuracy: 0.7909 - lr: 0.0010\n",
            "Epoch 73/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0442 - accuracy: 0.7651 - val_loss: 0.0416 - val_accuracy: 0.7867 - lr: 0.0010\n",
            "Epoch 74/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0439 - accuracy: 0.7673 - val_loss: 0.0424 - val_accuracy: 0.7772 - lr: 0.0010\n",
            "Epoch 75/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0444 - accuracy: 0.7635 - val_loss: 0.0430 - val_accuracy: 0.7743 - lr: 0.0010\n",
            "Epoch 76/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0441 - accuracy: 0.7662 - val_loss: 0.0476 - val_accuracy: 0.7497 - lr: 0.0010\n",
            "Epoch 77/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0401 - accuracy: 0.7895 - val_loss: 0.0374 - val_accuracy: 0.8021 - lr: 5.0000e-04\n",
            "Epoch 78/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0382 - accuracy: 0.7949 - val_loss: 0.0360 - val_accuracy: 0.8131 - lr: 5.0000e-04\n",
            "Epoch 79/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.0373 - accuracy: 0.7977 - val_loss: 0.0380 - val_accuracy: 0.7911 - lr: 5.0000e-04\n",
            "Epoch 80/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0369 - accuracy: 0.7992 - val_loss: 0.0334 - val_accuracy: 0.8219 - lr: 5.0000e-04\n",
            "Epoch 81/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0365 - accuracy: 0.8006 - val_loss: 0.0358 - val_accuracy: 0.8041 - lr: 5.0000e-04\n",
            "Epoch 82/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0367 - accuracy: 0.7979 - val_loss: 0.0346 - val_accuracy: 0.8151 - lr: 5.0000e-04\n",
            "Epoch 83/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0362 - accuracy: 0.8003 - val_loss: 0.0327 - val_accuracy: 0.8275 - lr: 5.0000e-04\n",
            "Epoch 84/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0362 - accuracy: 0.8017 - val_loss: 0.0364 - val_accuracy: 0.7998 - lr: 5.0000e-04\n",
            "Epoch 85/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0362 - accuracy: 0.8013 - val_loss: 0.0338 - val_accuracy: 0.8188 - lr: 5.0000e-04\n",
            "Epoch 86/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0359 - accuracy: 0.8027 - val_loss: 0.0361 - val_accuracy: 0.8039 - lr: 5.0000e-04\n",
            "Epoch 87/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0361 - accuracy: 0.8012 - val_loss: 0.0378 - val_accuracy: 0.7919 - lr: 5.0000e-04\n",
            "Epoch 88/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0359 - accuracy: 0.8002 - val_loss: 0.0363 - val_accuracy: 0.8043 - lr: 5.0000e-04\n",
            "Epoch 89/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0357 - accuracy: 0.8033 - val_loss: 0.0361 - val_accuracy: 0.8077 - lr: 5.0000e-04\n",
            "Epoch 90/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0357 - accuracy: 0.8028 - val_loss: 0.0350 - val_accuracy: 0.8120 - lr: 5.0000e-04\n",
            "Epoch 91/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0358 - accuracy: 0.8039 - val_loss: 0.0347 - val_accuracy: 0.8112 - lr: 5.0000e-04\n",
            "Epoch 92/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0356 - accuracy: 0.8042 - val_loss: 0.0355 - val_accuracy: 0.8059 - lr: 5.0000e-04\n",
            "Epoch 93/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0356 - accuracy: 0.8049 - val_loss: 0.0362 - val_accuracy: 0.8025 - lr: 5.0000e-04\n",
            "Epoch 94/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0357 - accuracy: 0.8039 - val_loss: 0.0348 - val_accuracy: 0.8101 - lr: 5.0000e-04\n",
            "Epoch 95/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0355 - accuracy: 0.8033 - val_loss: 0.0322 - val_accuracy: 0.8281 - lr: 5.0000e-04\n",
            "Epoch 96/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0357 - accuracy: 0.8042 - val_loss: 0.0313 - val_accuracy: 0.8368 - lr: 5.0000e-04\n",
            "Epoch 97/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0356 - accuracy: 0.8055 - val_loss: 0.0347 - val_accuracy: 0.8115 - lr: 5.0000e-04\n",
            "Epoch 98/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0354 - accuracy: 0.8060 - val_loss: 0.0359 - val_accuracy: 0.8026 - lr: 5.0000e-04\n",
            "Epoch 99/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0356 - accuracy: 0.8037 - val_loss: 0.0345 - val_accuracy: 0.8099 - lr: 5.0000e-04\n",
            "Epoch 100/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0354 - accuracy: 0.8049 - val_loss: 0.0350 - val_accuracy: 0.8109 - lr: 5.0000e-04\n",
            "Epoch 101/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0353 - accuracy: 0.8071 - val_loss: 0.0338 - val_accuracy: 0.8183 - lr: 5.0000e-04\n",
            "Epoch 102/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0352 - accuracy: 0.8080 - val_loss: 0.0367 - val_accuracy: 0.7988 - lr: 5.0000e-04\n",
            "Epoch 103/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0354 - accuracy: 0.8058 - val_loss: 0.0336 - val_accuracy: 0.8179 - lr: 5.0000e-04\n",
            "Epoch 104/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0353 - accuracy: 0.8074 - val_loss: 0.0332 - val_accuracy: 0.8219 - lr: 5.0000e-04\n",
            "Epoch 105/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0353 - accuracy: 0.8056 - val_loss: 0.0326 - val_accuracy: 0.8261 - lr: 5.0000e-04\n",
            "Epoch 106/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0352 - accuracy: 0.8076 - val_loss: 0.0419 - val_accuracy: 0.7732 - lr: 5.0000e-04\n",
            "Epoch 107/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0353 - accuracy: 0.8063 - val_loss: 0.0341 - val_accuracy: 0.8180 - lr: 5.0000e-04\n",
            "Epoch 108/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0352 - accuracy: 0.8069 - val_loss: 0.0329 - val_accuracy: 0.8249 - lr: 5.0000e-04\n",
            "Epoch 109/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0354 - accuracy: 0.8053 - val_loss: 0.0350 - val_accuracy: 0.8087 - lr: 5.0000e-04\n",
            "Epoch 110/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0353 - accuracy: 0.8068 - val_loss: 0.0361 - val_accuracy: 0.8041 - lr: 5.0000e-04\n",
            "Epoch 111/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0352 - accuracy: 0.8085 - val_loss: 0.0353 - val_accuracy: 0.8109 - lr: 5.0000e-04\n",
            "Epoch 112/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0353 - accuracy: 0.8058 - val_loss: 0.0375 - val_accuracy: 0.7979 - lr: 5.0000e-04\n",
            "Epoch 113/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0353 - accuracy: 0.8072 - val_loss: 0.0350 - val_accuracy: 0.8096 - lr: 5.0000e-04\n",
            "Epoch 114/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.0353 - accuracy: 0.8062 - val_loss: 0.0397 - val_accuracy: 0.7814 - lr: 5.0000e-04\n",
            "Epoch 115/125\n",
            "781/781 [==============================] - 48s 62ms/step - loss: 0.0351 - accuracy: 0.8079 - val_loss: 0.0326 - val_accuracy: 0.8268 - lr: 5.0000e-04\n",
            "Epoch 116/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0352 - accuracy: 0.8079 - val_loss: 0.0364 - val_accuracy: 0.7999 - lr: 5.0000e-04\n",
            "Epoch 117/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0351 - accuracy: 0.8091 - val_loss: 0.0324 - val_accuracy: 0.8300 - lr: 5.0000e-04\n",
            "Epoch 118/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0350 - accuracy: 0.8084 - val_loss: 0.0322 - val_accuracy: 0.8267 - lr: 5.0000e-04\n",
            "Epoch 119/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0351 - accuracy: 0.8083 - val_loss: 0.0370 - val_accuracy: 0.7958 - lr: 5.0000e-04\n",
            "Epoch 120/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0353 - accuracy: 0.8064 - val_loss: 0.0330 - val_accuracy: 0.8217 - lr: 5.0000e-04\n",
            "Epoch 121/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0350 - accuracy: 0.8094 - val_loss: 0.0324 - val_accuracy: 0.8275 - lr: 5.0000e-04\n",
            "Epoch 122/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0350 - accuracy: 0.8093 - val_loss: 0.0352 - val_accuracy: 0.8124 - lr: 5.0000e-04\n",
            "Epoch 123/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.0351 - accuracy: 0.8084 - val_loss: 0.0349 - val_accuracy: 0.8122 - lr: 5.0000e-04\n",
            "Epoch 124/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0349 - accuracy: 0.8096 - val_loss: 0.0319 - val_accuracy: 0.8314 - lr: 5.0000e-04\n",
            "Epoch 125/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 0.0349 - accuracy: 0.8076 - val_loss: 0.0349 - val_accuracy: 0.8137 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb7f9e08550>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lLR3ULJHYOr",
        "outputId": "1bb2c571-aa90-4f3c-b344-1fc51036c149"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 14ms/step - loss: 0.0349 - accuracy: 0.8137\n",
            "\n",
            "Test result: 81.370 loss: 0.035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hfxZ5HaeHYfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y1bkathNHYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TL8tPc1kHYlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xSNBX6PBHYov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QQlPJm9bHYwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vK97fSkLHYz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "If218PGbGTWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vL8m5CD1GTYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EQfqTO5WGTbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iAlELa73GTd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nj4OgGotGTgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MLVjlZuwGTjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WLsOBa8iGTmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_TNC9U7eGTqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}